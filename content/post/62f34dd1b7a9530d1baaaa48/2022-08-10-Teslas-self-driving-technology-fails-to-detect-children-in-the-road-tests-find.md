+++
title = "Tesla’s self-driving technology fails to detect children in the road, tests find"
description = "Professional test driver using Tesla’s Full Self-Driving mode repeatedly hit a child-sized mannequin in its path"
date = "2022-08-10 06:19:40"
slug = "62f34dd1b7a9530d1baaaa48"
image = "https://i.imgur.com/CFyFSQC.jpg"
score = "2417"
categories = ['children', 'teslas', 'road']
+++

Professional test driver using Tesla’s Full Self-Driving mode repeatedly hit a child-sized mannequin in its path

## Highlights

- The Dawn Project claims Tesla’s Full Self-Driving (FSD) Beta software repeatedly hit a stationary, child-sized mannequin in its path.
- Dawn Project's founder, Dan O’Dowd, called the results “deeply disturbing” Company chief “Elon Musk says Tesla's Full Self Driving software is ‘amazing’,’d added.
- In June, the National Highway Traffic Safety Administration (NHTSA), said it was expanding an investigation into 830,000 Tesla cars across all four current model lines.
- The agency has investigated 30 crashes involving Teslas equipped with automated driving systems, 19 of them fatal.

---

{{< rawhtml >}}
  <p class="article-category">
    <a target="_blank" href="https://www.theguardian.com/technology/2022/aug/09/tesla-self-driving-technology-safety-children">READ THE ORIGINAL ARTICLE</a>
  </p>
{{< /rawhtml >}}
